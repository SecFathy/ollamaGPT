
<h1 align="center">🧠 ollama GPT</h1>

<p align="center">
A beautiful, blazing-fast <strong>ChatGPT-style interface</strong> that runs locally on your machine using <a href="https://ollama.com/">Ollama</a> LLMs. <br>
No API keys. No limits. Just your own personal AI assistant, self-hosted and in your control.
</p>

<p align="center">
  <img src="https://img.shields.io/badge/Powered%20By-Ollama-blue?style=flat-square" />
  <img src="https://img.shields.io/badge/Stack-Full--Stack%20TS-green?style=flat-square" />
  <img src="https://img.shields.io/badge/UI-ChatGPT--Inspired-purple?style=flat-square" />
  <img src="https://img.shields.io/badge/License-MIT-red?style=flat-square" />
</p>

---

## 🚀 What is ollama GPT?

> A **self-hosted ChatGPT alternative** that connects directly to your locally running **Ollama** models.

Designed for developers, power users, and AI enthusiasts who want **zero restrictions**, **custom LLM control**, and a **modern interface** — all running on your own machine.

---

## ✨ Key Features

✅ **Unlimited Chatting** – No rate limits, no API key headaches  
👥 **Multi-user Support** – Register and manage multiple users  
🚫 **Keyword Filtering** – Block unwanted prompts or misuse  
🛑 **User Access Control** – Enable/Disable users anytime  
⚡ **Lightweight Engine** – Runs on in-memory DB, fast and snappy  
💬 **Live Token Streaming** – See responses appear in real-time  
🎨 **ChatGPT-Inspired UI** – Beautiful and familiar interface  
🔒 **Authentication** – Local login system with hashed passwords  
🐳 **Docker Ready** – One-command deployment via Docker Compose  

---

## 🧠 Powered by Ollama

ollama GPT acts as a frontend and proxy layer for your local Ollama LLM server.

➡️ [https://ollama.com](https://ollama.com)

Works with any Ollama-supported model like:

- `deepseek-coder`
- `codellama`
- `mistral`
- `llama2`
- or even your own fine-tuned model!



## 📦 Getting Started

### 1. Clone the project

```bash
git clone https://github.com/SecFathy/ollamaGPT.git
cd ollamaGPT
```

### 2. Install dependencies

```bash
npm install

```

### 3. Start Ollama

Make sure Ollama is installed and running a model:

```bash
ollama run deepseek-coder-v2
```

### 4. Run the app

#### Option A: Dev mode

```bash

npm run dev
```

#### Option B: Docker 🐳

```bash
docker-compose up --build
```

---

## 📸 Screenshots


---

## 💬 Why Use ollama GPT?

- You own the infrastructure 🧠
- No hidden limitations or paid APIs 💸
- Customize everything: models, access, filters 🔧
- Looks and feels like ChatGPT — but offline ⚡

---


## 📄 License

MIT – Free to use, extend, and host forever.

---


